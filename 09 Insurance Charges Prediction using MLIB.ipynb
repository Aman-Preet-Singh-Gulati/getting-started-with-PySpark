{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5911IBZ5SKW"
   },
   "source": [
    "https://www.kaggle.com/code/gloriousc/insurance-forecast-by-using-linear-regression/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7HmVVDTkDKK",
    "outputId": "8bda846c-b8b1-4d76-f697-c45e5b13dda6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 29 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 50.5 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=e7f2c07504fba8fcc5d809f6d48a97b76ea070d67e9fbc90767d4859ebd0c1fd\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTtpkR_pi-LV"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this article we will be working to predict the insurance charges that will be imposed on a customer who is willing to take the **health inusrance** and for predicting the same PySpark's MLIB library is the driver to execute the whole process of this Machine learning pipeline.\n",
    "\n",
    "We are gonna work with the real world insurance dataset that I've downloaded from **[Kaggle](https://https://www.kaggle.com/code/gloriousc/insurance-forecast-by-using-linear-regression/data)**. I'll be providing the link for your reference, so without any further wait let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR8oKDqnkO6K"
   },
   "source": [
    "## Importing all the libraries from PySpark\n",
    "\n",
    "Our very first step is to import all the libraries from PySpark which will be required in a complete machine learning process i.e. from the **data preprocessing** to **model building phase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hpLLJ7wB5UXc"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.stat import Correlation\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sffboBR9jC7u"
   },
   "source": [
    "## Setting up the Spark Session for PySpark package\n",
    "\n",
    "In this step the Spark object will be created through which we can access all the **deliverables, functions and libraries** that Spark has to offer and the new **virtual environment will be created** so that we can do all the steps that are involved in ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "CmsK1MSEmi2w",
    "outputId": "7af54362-3436-45bf-c8dd-604e9f421997"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a51988c7ea94:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Insuarance cost prediction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8ca28cfa10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark  = SparkSession.builder.appName(\"Insuarance cost prediction\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HW7MjbhKn_Tm"
   },
   "source": [
    "## Reading the insurance dataset using Pyspark\n",
    "\n",
    "In this section we will be reading the dataset using **read.csv()** function of PySpark before moving forward with further process let's know more about the dataset.\n",
    "\n",
    "So in this particular dataset we have all the essential high priority features that could help us to detect the life insurance charges which are possible to embrase on card holder.\n",
    "\n",
    "**Features are as follows:**\n",
    "\n",
    "1. **Age**: Age of the customer.\n",
    "2. **BMI**: Body Mass Index of the individual.\n",
    "3. **Childeren**: Number of childeren he/she have.\n",
    "4. **Smoker**: Is that individual a frequent Smoker or not.\n",
    "5. **Region**: Which region/part he/she lives in and,\n",
    "\n",
    "**Charges** column is our **target/independent** feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7P6Vgc3bzqx",
    "outputId": "4afa4d51-ff7c-4471-b185-31396af263f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"insurance.csv\", inferSchema = True, header = True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrjoR9wHGczu"
   },
   "source": [
    "**Code breakdown:**\n",
    "\n",
    "As discussed we have read the insurance dataset which was in the **CSV** format using **read.csv** function keeping the **inferSchema** parameter as **True** which will return the real data-type of each column along with that we kept the **header** as **True** so that first row would be treated as header of the column.\n",
    "\n",
    "At the last we have displayed the data using the PySpark's show method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7yDHuLlIAxe"
   },
   "source": [
    "Now it's time to **statistically analyze our dataset** for that we will start by extracting the total number of records which are present in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMg0ET6-cdDn",
    "outputId": "8af559f6-7d9c-4d71-842e-c1b0b9fe3405"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4AewG6bINmj"
   },
   "source": [
    "**Inference:** So from the above output we can state that there are total of **1338** records in the dataset which we were able to get with the help of **count** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rFN3Y0v7cq51",
    "outputId": "5a39340c-6d96-4508-aecd-4bcc9e00b334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns are: 7\n",
      "And those columns are: ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of columns are: {}\".format(len(data.columns)))\n",
    "print(\"And those columns are: {}\".format(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4HSP1deI7zh"
   },
   "source": [
    "**Inference:** In the above code we tried to get as much information about the columns present for the analysis and conclusively we got to know that it have total **7** columns and there **name** as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndg0zv0hK7Sk"
   },
   "source": [
    "Now let's look at the **Schema** i.e. the structure of the dataset where we would be able to know about **type of each column**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wc-TE1bucw5e",
    "outputId": "8251e8c8-be65-4272-e6dc-0892780e2ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- charges: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk9xgn_qK3Xi"
   },
   "source": [
    "**Inference:** So from the above output we can see that adjacent to each feature we can see it's **data type** and also a flag condition where it states whether the column can have **null values or not**.\n",
    "\n",
    "**Note:** If you closely look at the result then one can see the **sex,childeren, smoker and region features are in the string format** but they are actually **categorical variables** hence in the coming discussion we will convert them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLDnnXR0OoTA"
   },
   "source": [
    "Now it's time to see the statistical inferences of the dataset so that we can get some information related to the **count, mean, standard deviation, minimum and maximum values** of the corresponding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bWV8ZwKcytD",
    "outputId": "5e81c06c-61d3-441f-ccec-e8b88cd8a5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+------------------+-----------------+------+---------+------------------+\n",
      "|summary|               age|   sex|               bmi|         children|smoker|   region|           charges|\n",
      "+-------+------------------+------+------------------+-----------------+------+---------+------------------+\n",
      "|  count|              1338|  1338|              1338|             1338|  1338|     1338|              1338|\n",
      "|   mean| 39.20702541106129|  null|30.663396860986538|  1.0949177877429|  null|     null|13270.422265141257|\n",
      "| stddev|14.049960379216147|  null| 6.098186911679012|1.205492739781914|  null|     null|12110.011236693992|\n",
      "|    min|                18|female|             15.96|                0|    no|northeast|         1121.8739|\n",
      "|    max|                64|  male|             53.13|                5|   yes|southwest|       63770.42801|\n",
      "+-------+------------------+------+------------------+-----------------+------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgO1pH0CSV2O"
   },
   "source": [
    "**Inference:** So from the above output we can draw multiple inferenes where we can see each feature **count is same i.e. 1338** that means there are **no Null values** and **maximum age** in the data is **64** while the **minimum** is **18** similarly **max** number of **childeren** are **5** and **minumum** is **0** i.e. no child. So we can put into the note that describe function can give ample of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfHc1XaFTdB1"
   },
   "source": [
    "There is one more way to see the records and this one is similar to the ones who have previously came across pandas data processsing i.e. **head** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u88CGIluc4hI",
    "outputId": "bf591359-68b4-45f2-9b39-7a6f7b0cd452"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=19, sex='female', bmi=27.9, children=0, smoker='yes', region='southwest', charges=16884.924),\n",
       " Row(age=18, sex='male', bmi=33.77, children=1, smoker='no', region='southeast', charges=1725.5523),\n",
       " Row(age=28, sex='male', bmi=33.0, children=3, smoker='no', region='southeast', charges=4449.462),\n",
       " Row(age=33, sex='male', bmi=22.705, children=0, smoker='no', region='northwest', charges=21984.47061),\n",
       " Row(age=32, sex='male', bmi=28.88, children=0, smoker='no', region='northwest', charges=3866.8552)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zJ1PrfRTskH"
   },
   "source": [
    "**Inference:** As one can notice that it return the row object so from here we can assume that if we want to analyze the data per records i.e. of **each tuple** then grabbing them using **head** function could be a better approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A66JPR2XVTkA"
   },
   "source": [
    "## Correlation in variables\n",
    "\n",
    "Correlation is one of a kind technique which helps us in getting the **more accurate predictions** as it helps us know the **relationship between two or more variables** and return how likely they are **positively** or **negatively** related to it.\n",
    "\n",
    "\n",
    "In this particular problem statement we will be finding the correlation between all the **dependent variables** (continous/integer one only) and **independent variable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_E2QlvkediS",
    "outputId": "eb4ea36f-d9b6-4ce7-f200-479c541f7e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Age of the person and charges is : 0.299008193330648\n",
      "Correlation between BMI of the person and charges is : 0.19834096883362903\n"
     ]
    }
   ],
   "source": [
    "age = data.corr(\"age\", \"charges\")\n",
    "BMI = data.corr(\"bmi\", \"charges\")\n",
    "\n",
    "print(\"Correlation between Age of the person and charges is : {}\".format(age))\n",
    "print(\"Correlation between BMI of the person and charges is : {}\".format(BMI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQCCUpdZW46a"
   },
   "source": [
    "**Inference:** Correlation between the Age and insurance charges is equivalent to **0.30** while BMI and insurance charges are related to each other with **0.20** value.\n",
    "\n",
    "**Note:** We have only used two variables though logically we have multiple options but they are in the **string format so we can't put them in this analysis for now** but you guys can repeat the same process for them after the conversion step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSFnijcnYMtf"
   },
   "source": [
    "## String Indexer\n",
    "\n",
    "In this section of the article we will be converting the **string type features to valid categorical variables** so that our machine learning model should understand those features as we know that ML model only works when we have all the dependent variables in the numerical format.\n",
    "\n",
    "Hence, it is very important step to proceed for this **StringIndexer** function will come to rescue.\n",
    "\n",
    "**Note:** First we will be converting all the required fields to categorical variables and then look at the line by line explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSmQqS4-qom8"
   },
   "source": [
    "1. Changing the string type \"**sex**\" column to categorical variable using **String Indexer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hSCkHTJDfMJH"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "category = StringIndexer(inputCol = \"sex\", outputCol = \"gender_categorical\")\n",
    "categorised = category.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbybymEwgD4j",
    "outputId": "35c53885-ee69-43a7-e425-d933abbcb188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+------------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|gender_categorical|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|               1.0|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|               0.0|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|               0.0|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|               0.0|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|               0.0|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|               1.0|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|               1.0|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|               1.0|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|               0.0|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|               1.0|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|               0.0|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|               1.0|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|               0.0|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|               1.0|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|               0.0|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|               0.0|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|               1.0|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|               0.0|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|               0.0|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|               0.0|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorised.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2U7hACdq06w"
   },
   "source": [
    "2. Changing the string type \"**smoker**\" column to categorical variable using **String Indexer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "paNkKGL7gQNk"
   },
   "outputs": [],
   "source": [
    "category = StringIndexer(inputCol = \"smoker\", outputCol = \"smoker_categorical\")\n",
    "categorised = category.fit(categorised).transform(categorised) # Note that here I have used categorised in place of data as our updated data is in the new DataFrame i.e. \"categorised\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljyqcQFSg3jj",
    "outputId": "c3026d15-0c21-4a6e-c307-455d0cc96445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+------------------+------------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|gender_categorical|smoker_categorical|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+------------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|               1.0|               1.0|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|               0.0|               0.0|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|               0.0|               0.0|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|               0.0|               0.0|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|               0.0|               0.0|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|               1.0|               0.0|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|               1.0|               0.0|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|               1.0|               0.0|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|               0.0|               0.0|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|               1.0|               0.0|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|               0.0|               0.0|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|               1.0|               1.0|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|               0.0|               0.0|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|               1.0|               0.0|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|               0.0|               1.0|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|               0.0|               0.0|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|               1.0|               0.0|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|               0.0|               0.0|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|               0.0|               0.0|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|               0.0|               1.0|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorised.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a3VM31Vq8u-"
   },
   "source": [
    "3. Changing the string type \"**region**\" column to categorical variable using **String Indexer**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0gVqB1XQg5Rh"
   },
   "outputs": [],
   "source": [
    "category = StringIndexer(inputCol = \"region\", outputCol = \"region_categorical\")\n",
    "categorised = category.fit(categorised).transform(categorised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYbKtKelhIS3",
    "outputId": "b2b4d63b-b7ed-4598-b14c-992b8c6d4cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+------------------+------------------+------------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|gender_categorical|smoker_categorical|region_categorical|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+------------------+------------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|               1.0|               1.0|               2.0|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|               0.0|               0.0|               0.0|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|               0.0|               0.0|               0.0|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|               0.0|               0.0|               1.0|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|               0.0|               0.0|               1.0|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|               1.0|               0.0|               0.0|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|               1.0|               0.0|               0.0|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|               1.0|               0.0|               1.0|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|               0.0|               0.0|               3.0|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|               1.0|               0.0|               1.0|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|               0.0|               0.0|               3.0|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|               1.0|               1.0|               0.0|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|               0.0|               0.0|               2.0|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|               1.0|               0.0|               0.0|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|               0.0|               1.0|               0.0|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|               0.0|               0.0|               2.0|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|               1.0|               0.0|               3.0|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|               0.0|               0.0|               3.0|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|               0.0|               0.0|               2.0|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|               0.0|               1.0|               2.0|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorised.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcglmrPZrbqK"
   },
   "source": [
    "**Code breakdown:**\n",
    "\n",
    "1. Firstly we imported the **StringIndexer** function from the **ml.feature** package of Pyspark.\n",
    "2. Then for converting the **sex column** to relevant categorical feature we took up the imported object and in the **inpuCol** parameter **original feature** was passed while in **outputCol** feature we passed the name of the **converted feature**.\n",
    "3. Similarly we did the same for all the columns that were required to be converted to categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzVxdr4OzItU"
   },
   "source": [
    "## Vector Assembler \n",
    "\n",
    "As we already know that PySpark needs the combined level of features i.e. **all the features should be piled up in single column** and they all will be treated as one single entity in the form of **list**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wHnVyUZwhKft"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7zRGlrmzwcv"
   },
   "source": [
    "**Inference:** So we have imported the **Vector** from the **linalg** package of ML and **VectorAssembler** from **feature** package of ML so that we can pile up all the dependent fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZZTXalMhsuu",
    "outputId": "3b412bdf-876c-4919-d989-6a382badf379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'sex',\n",
       " 'bmi',\n",
       " 'children',\n",
       " 'smoker',\n",
       " 'region',\n",
       " 'charges',\n",
       " 'gender_categorical',\n",
       " 'smoker_categorical',\n",
       " 'region_categorical']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorised.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZDiL_X60Ihh"
   },
   "source": [
    "**Inference:** The columns which one can see in the above output are the total columns but we don't need the string ones instead the one which were changed to integer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "hwZlFJ6uhhaI"
   },
   "outputs": [],
   "source": [
    "concatenating  = VectorAssembler(inputCols=[\"age\",\"bmi\", \"children\", \"gender_categorical\", \"smoker_categorical\", \"region_categorical\"],\n",
    "                                 outputCol=\"features\")\n",
    "results = concatenating.transform(categorised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEtIFkmB0gg2"
   },
   "source": [
    "**Inference:** While combining all the features we pass in all the relavant column names in the form of list as the **inputCol** paramater and then to see the changes as well we need to **transform** our original dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ukvpPrdivPB",
    "outputId": "dca6833e-7746-4895-aaf7-a72733fbe53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-----------+\n",
      "|features                     |charges    |\n",
      "+-----------------------------+-----------+\n",
      "|[19.0,27.9,0.0,1.0,1.0,2.0]  |16884.924  |\n",
      "|[18.0,33.77,1.0,0.0,0.0,0.0] |1725.5523  |\n",
      "|[28.0,33.0,3.0,0.0,0.0,0.0]  |4449.462   |\n",
      "|[33.0,22.705,0.0,0.0,0.0,1.0]|21984.47061|\n",
      "|[32.0,28.88,0.0,0.0,0.0,1.0] |3866.8552  |\n",
      "|[31.0,25.74,0.0,1.0,0.0,0.0] |3756.6216  |\n",
      "|[46.0,33.44,1.0,1.0,0.0,0.0] |8240.5896  |\n",
      "|[37.0,27.74,3.0,1.0,0.0,1.0] |7281.5056  |\n",
      "|[37.0,29.83,2.0,0.0,0.0,3.0] |6406.4107  |\n",
      "|[60.0,25.84,0.0,1.0,0.0,1.0] |28923.13692|\n",
      "|[25.0,26.22,0.0,0.0,0.0,3.0] |2721.3208  |\n",
      "|[62.0,26.29,0.0,1.0,1.0,0.0] |27808.7251 |\n",
      "|[23.0,34.4,0.0,0.0,0.0,2.0]  |1826.843   |\n",
      "|[56.0,39.82,0.0,1.0,0.0,0.0] |11090.7178 |\n",
      "|[27.0,42.13,0.0,0.0,1.0,0.0] |39611.7577 |\n",
      "|[19.0,24.6,1.0,0.0,0.0,2.0]  |1837.237   |\n",
      "|[52.0,30.78,1.0,1.0,0.0,3.0] |10797.3362 |\n",
      "|[23.0,23.845,0.0,0.0,0.0,3.0]|2395.17155 |\n",
      "|[56.0,40.3,0.0,0.0,0.0,2.0]  |10602.385  |\n",
      "|[30.0,35.3,0.0,0.0,1.0,2.0]  |36837.467  |\n",
      "+-----------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for_model = results.select(\"features\", \"charges\")\n",
    "for_model.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUILDrwaAsW2"
   },
   "source": [
    "**Inference:** Now we are creating a new DataFrame which we will send it across to our model for model creation.\n",
    "\n",
    "**Note:** In the show function we have used **truncate=False** that means now all the features in the list will show up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGkvhltEF6nu"
   },
   "source": [
    "## Train Test Split\n",
    "\n",
    "So by far we have done each step which is reqired in the **model building** phase hence now it's time to split out the dataset into **training** and **testing** form so that one will be used for training the model and other one will be to test the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nC553y7LjExL"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = for_model.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKL3dfJmHsCV"
   },
   "source": [
    "**Inference:** In the above randomsplit() function we can see that training data is of **70% (0.7)** and the testing data is of 30% (0.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5R-fNbbjSrD",
    "outputId": "cde0a761-9eb3-445e-d694-ac01cd9c972e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           charges|\n",
      "+-------+------------------+\n",
      "|  count|               951|\n",
      "|   mean|13568.140120188222|\n",
      "| stddev|12425.885456579752|\n",
      "|    min|         1121.8739|\n",
      "|    max|       63770.42801|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ORxvso2jZ5r",
    "outputId": "e17b3c05-fc08-43a5-995c-1d946f97812a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           charges|\n",
      "+-------+------------------+\n",
      "|  count|               387|\n",
      "|   mean|12538.821024444438|\n",
      "| stddev|11278.423261784697|\n",
      "|    min|         1149.3959|\n",
      "|    max|       48885.13561|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1U07Wu5cH95x"
   },
   "source": [
    "**Inference:** Describe function is used on top of both the splitted dataset and we can see multiple information about them like the total count of training set is **951** while the other one have **387**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLmQ13DNJuzt"
   },
   "source": [
    "## Model Building\n",
    "\n",
    "In this phase of the article we will be building our model using the **Linear Regression** algorithm as **we are dealing with continous group of features** so this is the best and go to choice for us in the current possible problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DH2m7Jcvjc1d"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJS6hlk1jjft",
    "outputId": "53c7c765-5536-48e4-c44c-2cd13d736377"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_d7bb227324ac"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LinearRegression(featuresCol= \"features\",\n",
    "                            labelCol=\"charges\")\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6WH5osJKZvw"
   },
   "source": [
    "Firstly we are embedding a **Linear Regression** object by passing in the **features** column that we have already seperated and the **label** column is our target feature i.e. \"**charges**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEEo1oo1juLw",
    "outputId": "69e5e654-4a0e-419b-f26d-5339bd0f4d40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_d7bb227324ac, numFeatures=6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model = lr_model.fit(train_data)\n",
    "training_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4siTNA-KK9JV"
   },
   "source": [
    "Then the LR object which we have created is being **fit with the training data** that we got from **randomSplit**() method, in the output one can see it returned the valid information about the model i.e. **number of features it holds - 6.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PtHlftWLZFX"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "So by far we are now done with model development phase so it's time to evaluate the model and get the inference of the same about whether it is worthy model or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RLOXO-CBj2xN"
   },
   "outputs": [],
   "source": [
    "output = training_model.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDD9c-tLNJKw"
   },
   "source": [
    "**Evaluate** function is to call all the metrics that are involved in the **model evaluation** phase so that we can make a decision regarding **accuracy of the model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFKee4xLkDDc",
    "outputId": "7e79d05b-4a6b-403f-90bf-f7a004f4e1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7477904623279588\n",
      "38900867.48971935\n",
      "4324.864277057295\n"
     ]
    }
   ],
   "source": [
    "print(output.r2)\n",
    "print(output.meanSquaredError)\n",
    "print(output.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNAH0e_0PY1G"
   },
   "source": [
    "Here are the results of all the valid evaluation metrics available:\n",
    "\n",
    "1. **R-squarred:** This metric explains about how much variance of the data is explained by the model.\n",
    "2. **Mean Squarred Error:** This basically returns the residual values of a regression fit line and moreover magnifies the large errors\n",
    "3. **Mean Absolute Error:** Does the same thing but this one focussed on minimizing the small errors which MSE might ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmnpaptoYOTS"
   },
   "source": [
    "**It's time to make preductions!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "llMyizG1kLcB"
   },
   "outputs": [],
   "source": [
    "features_unlabelled_data = test_data.select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "coK5GfeEkZOt"
   },
   "outputs": [],
   "source": [
    "final_pred = training_model.transform(features_unlabelled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XX63n-v2kmbW",
    "outputId": "bbe32690-111d-4f52-d487-bbcdcc292c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|(6,[0,1],[18.0,43...| 6310.418188362031|\n",
      "|(6,[0,1],[23.0,26...| 1989.316776915317|\n",
      "|(6,[0,1],[23.0,41...|7156.7732642268475|\n",
      "|(6,[0,1],[27.0,23...|1817.4615575488478|\n",
      "|(6,[0,1],[28.0,38...| 7080.368253071751|\n",
      "|(6,[0,1],[33.0,30...| 5675.188716607967|\n",
      "|(6,[0,1],[36.0,29...| 6219.912165607651|\n",
      "|(6,[0,1],[40.0,41...|11215.513433552713|\n",
      "|(6,[0,1],[41.0,33...|  8727.23539810832|\n",
      "|(6,[0,1],[41.0,40...|10978.770010436912|\n",
      "|(6,[0,1],[49.0,35...|  11447.0884482815|\n",
      "|(6,[0,1],[49.0,36...|11779.282079608669|\n",
      "|(6,[0,1],[50.0,25...|8146.7815362595775|\n",
      "|(6,[0,1],[52.0,34...|11585.797458992425|\n",
      "|(6,[0,1],[53.0,31...|10906.129194107065|\n",
      "|(6,[0,1],[56.0,34...|12668.895957973038|\n",
      "|(6,[0,1],[62.0,39...|15972.967064820206|\n",
      "|(6,[0,1],[63.0,41...|16732.804535685922|\n",
      "|(6,[0,1],[64.0,40...|16643.702726493306|\n",
      "|[18.0,20.79,0.0,1...|-689.4691767537097|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OsU5lBcWtBF"
   },
   "source": [
    "**Code breakdown:** \n",
    "This is the final step where we will be doing the predictions based on the model we have built and compare the actual result with the predicted one.\n",
    "\n",
    "1. Created a DataFrame for the unlabbelled data i.e. our features column\n",
    "2. Then we have transform the unlabbelled data using the same function we used before.\n",
    "3. At the last we show the prediction results which one can see in the above output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fyMZ9hUvLJ-"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Finally we are able to predict the insuarance charges with the help of Pyspark's MLIB library we have performed every step from the ground level i.e. from reading the dataset to the making the predictions from the evaluated model. \n",
    "\n",
    "Let's discuss in a descriptive way whatever we have learnt so far!\n",
    "\n",
    "1. First of all we read the insurance dataset which was real-world dataset from Kaggle\n",
    "2. Then we performed the data preprocessing steps where we got to know about the dataset's columns, statistics and changing the string type columns to categorical variables.\n",
    "3. Then comes the Model building phase where we build the Linear Regression model using Pyspark's MLIB library.\n",
    "4. At the last we evaluated the model and made the predictions from the same."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Insurance Charges Prediction using MLIB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
